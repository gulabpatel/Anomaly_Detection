{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace_Transformer_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/Anomaly_Detection_Python/blob/main/HuggingFace_Transformer_Pipeline_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCM2XIGlgNG-"
      },
      "source": [
        "![Hugging Face](https://miro.medium.com/max/2000/1*Z4mGaMsu34LfyE76QAi9qA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZyI24eXcEEJ"
      },
      "source": [
        "# Using HuggingFace\n",
        "\n",
        "In this tutorial, we will learn how to use the various functionalities offered by [HuggingFace](https://huggingface.co/).\n",
        "\n",
        "## About Hugging Face\n",
        "\n",
        "- HuggingFace is 'On a mission to solve NLP, One commit at a time', as per their tagline. \n",
        "\n",
        "- The HuggingFace Transformer library is closing on 26K Stars on GitHub now and provides state-of-the-art Transformer Based Models, their pretrained weights and a lots more (as we will see today)\n",
        "\n",
        "- They recently released their Tokenisers library\n",
        "\n",
        "\n",
        "They have originally used Rust, so that's an added advantage.\n",
        "\n",
        "\n",
        "Help is available [here](https://www.youtube.com/watch?v=B5M_F9dYHOM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCGc19nd3TZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5a84cf-76aa-494a-eb9b-10353a261855"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXMZYhxZ-7H8"
      },
      "source": [
        "# Pipeline\n",
        "\n",
        "https://github.com/huggingface/transformers#quick-tour-of-pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTaHAhi14usQ"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5conX00349D8"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsIp762F44pA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571dde1b-fee3-4e7c-c7f9-1cb86ee36992"
      },
      "source": [
        "nlp = pipeline('sentiment-analysis')\n",
        "nlp('We are very happy to include pipeline into the transformers repository.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9978193640708923}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1-ibaH-5L6P"
      },
      "source": [
        "## Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqN6XDF5ASb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51bc3570-49b5-4d40-ae9d-c2d6f7c53109"
      },
      "source": [
        "nlp = pipeline('question-answering')\n",
        "nlp({\n",
        "    'question': 'What is my name ?',\n",
        "    'context': 'My name is Rachit, I work at HuggingFace'\n",
        "})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Rachit', 'end': 17, 'score': 0.9968027472496033, 'start': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGe199t65pVg"
      },
      "source": [
        "## Predicting Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d6NvCks5NnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636fe899-54c4-4335-a052-062e846b1aaa"
      },
      "source": [
        "nlp = pipeline('fill-mask')\n",
        "nlp('I hope you <mask> this video')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.7073913812637329,\n",
              "  'sequence': 'I hope you enjoyed this video',\n",
              "  'token': 3776,\n",
              "  'token_str': ' enjoyed'},\n",
              " {'score': 0.1367352455854416,\n",
              "  'sequence': 'I hope you enjoy this video',\n",
              "  'token': 2254,\n",
              "  'token_str': ' enjoy'},\n",
              " {'score': 0.1335318684577942,\n",
              "  'sequence': 'I hope you liked this video',\n",
              "  'token': 6640,\n",
              "  'token_str': ' liked'},\n",
              " {'score': 0.005779118277132511,\n",
              "  'sequence': 'I hope you like this video',\n",
              "  'token': 101,\n",
              "  'token_str': ' like'},\n",
              " {'score': 0.005615219473838806,\n",
              "  'sequence': 'I hope you appreciated this video',\n",
              "  'token': 10874,\n",
              "  'token_str': ' appreciated'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4SW0acf81ZQ"
      },
      "source": [
        "## NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZA4oFr-8PpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef04688-8558-43ce-a17c-34315a2c9c92"
      },
      "source": [
        "nlp = pipeline('ner')\n",
        "nlp('It is me, Rachit, I work at HuggingFace')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 12,\n",
              "  'entity': 'I-PER',\n",
              "  'index': 5,\n",
              "  'score': 0.9992461800575256,\n",
              "  'start': 10,\n",
              "  'word': 'Ra'},\n",
              " {'end': 15,\n",
              "  'entity': 'I-PER',\n",
              "  'index': 6,\n",
              "  'score': 0.988210916519165,\n",
              "  'start': 12,\n",
              "  'word': '##chi'},\n",
              " {'end': 16,\n",
              "  'entity': 'I-PER',\n",
              "  'index': 7,\n",
              "  'score': 0.991302490234375,\n",
              "  'start': 15,\n",
              "  'word': '##t'},\n",
              " {'end': 30,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 12,\n",
              "  'score': 0.9990648031234741,\n",
              "  'start': 28,\n",
              "  'word': 'Hu'},\n",
              " {'end': 35,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 13,\n",
              "  'score': 0.9934505820274353,\n",
              "  'start': 30,\n",
              "  'word': '##gging'},\n",
              " {'end': 36,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 14,\n",
              "  'score': 0.9981080889701843,\n",
              "  'start': 35,\n",
              "  'word': '##F'},\n",
              " {'end': 39,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 15,\n",
              "  'score': 0.9968755841255188,\n",
              "  'start': 36,\n",
              "  'word': '##ace'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AW2ykR0HBSI"
      },
      "source": [
        "nlp.model.save_pretrained('...')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amASDwJA_P01"
      },
      "source": [
        "# Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcbUda0I9cfN"
      },
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNFL0TUwC4Dr"
      },
      "source": [
        "tokeniser = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b77RqrJgDH-p"
      },
      "source": [
        "## Single Word Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuYAjdLGC6VT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5aff368-f969-463a-8e4d-dcf3c435a787"
      },
      "source": [
        "text = \"let us see how this turns\"\n",
        "indexed_tokens = tokeniser.encode(text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "model.eval()\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "model.to('cuda')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNylT-NaC9UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9549336a-c330-4469-b787-d25790f6ab64"
      },
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(tokens_tensor)\n",
        "  predictions = outputs[0]\n",
        "\n",
        "print(outputs[0].shape)\n",
        "\n",
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokeniser.decode(indexed_tokens + [predicted_index])\n",
        "\n",
        "print(predicted_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 6, 50257])\n",
            "let us see how this turns out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzxsYVVMDcZf"
      },
      "source": [
        "## Looping for multi-word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FyWdPiNDZLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e722a0-d2d2-449d-b803-b3d338cab324"
      },
      "source": [
        "chars = 0\n",
        "text = \"i am very exited to present to you this\"\n",
        "while chars<50:\n",
        "  chars += 1\n",
        "  indexed_tokens = tokeniser.encode(text)\n",
        "  tokens_tensors = torch.tensor([indexed_tokens])\n",
        "  tokens_tensors = tokens_tensors.to('cuda')\n",
        "#  model = model.to('cuda')\n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensors)\n",
        "    predictions = outputs[0]\n",
        "  predicted_index = torch.argmax(predictions[0,-1,:]).item()\n",
        "  text = tokeniser.decode(indexed_tokens + [predicted_index])\n",
        "\n",
        "print(text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i am very exited to present to you this new book. I am very excited to share with you the first chapter of the book, \"The Secret of the Soul.\"\n",
            "\n",
            "\n",
            "The Secret of the Soul is a book that I have been reading for over a year now. I have been\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aCthtSaD7dh"
      },
      "source": [
        "## OR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I1NMc7KDe77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b04a4ec-239f-4329-87e1-b83e9d40d229"
      },
      "source": [
        "!git clone https://github.com/huggingface/pytorch-transformers.git"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch-transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDjX6DBED89q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e9cd68-1822-4868-c906-27e7d174b2f5"
      },
      "source": [
        "!python pytorch-transformers/examples/text-generation/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --length=100 \\\n",
        "    --model_name_or_path=gpt2 \\"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/03/2021 15:57:55 - WARNING - __main__ -   device: cuda, n_gpu: 1, 16-bits training: False\n",
            "04/03/2021 15:58:14 - INFO - __main__ -   Namespace(device=device(type='cuda'), fp16=False, k=0, length=100, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prefix='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> i am very excited to present to you this\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "2021-04-03 15:58:30.511049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "i am very excited to present to you this blend!\n",
            "\n",
            "\"From the moment you had the opportunity to sample the original Mjuushin no Čve ( A New World Tea), you immediately became hooked!\"\n",
            "\n",
            "This 3oz. glass bottle from Punglish brings a massive candy coating to this beast of a lemonade stand, something that piques your interest. In the past I've tried the unsweetened fruit in a vanilla-flavored flake — had it done. With my vanilla blend, I've always\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIXrfA4WIzNH"
      },
      "source": [
        "# Summarising text using HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mvwkDMMKLFM"
      },
      "source": [
        "text = 'Shakespeare occupies a position unique in world literature. Other poets, such as Homer and Dante, and novelists, such as Leo Tolstoy and Charles Dickens, have transcended national barriers, but no writer’s living reputation can compare to that of Shakespeare, whose plays, written in the late 16th and early 17th centuries for a small repertory theatre, are now performed and read more often and in more countries than ever before. The prophecy of his great contemporary, the poet and dramatist Ben Jonson, that Shakespeare “was not of an age, but for all time,” has been fulfilled. It may be audacious even to attempt a definition of his greatness, but it is not so difficult to describe the gifts that enabled him to create imaginative visions of pathos and mirth that, whether read or witnessed in the theatre, fill the mind and linger there. He is a writer of great intellectual rapidity, perceptiveness, and poetic power. Other writers have had these qualities, but with Shakespeare the keenness of mind was applied not to abstruse or remote subjects but to human beings and their complete range of emotions and conflicts. Other writers have applied their keenness of mind in this way, but Shakespeare is astonishingly clever with words and images, so that his mental energy, when applied to intelligible human situations, finds full and memorable expression, convincing and imaginatively stimulating. As if this were not enough, the art form into which his creative energies went was not remote and bookish but involved the vivid stage impersonation of human beings, commanding sympathy and inviting vicarious participation. Thus, Shakespeare’s merits can survive translation into other languages and into cultures remote from that of Elizabethan England.'"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR9aT7VBI8zs"
      },
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vh8uAGI8wF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9305d9da-44f6-48db-d7e4-c5f3b0c0b7c4"
      },
      "source": [
        "inputs = tokenizer.batch_encode_plus([text], max_length=1024, return_tensors='pt')\n",
        "\n",
        "summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=100, early_stopping=False)\n",
        "\n",
        "for ids in summary_ids:\n",
        "    short = tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "\n",
        "    print(len(text), len(short))\n",
        "    print(short)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1761 341\n",
            "Shakespeare occupies a position unique in world literature. He is a writer of great intellectual rapidity, perceptiveness, and poetic power. Other writers have had these qualities, but with Shakespeare the keenness of mind was applied not to abstruse or remote subjects but to human beings and their complete range of emotions and conflicts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsjTjYg9eFfV"
      },
      "source": [
        "HuggingFace Tranformers: https://github.com/huggingface/transformers\n",
        "\n",
        "BART: https://arxiv.org/abs/1910.13461\n",
        "\n",
        "Curious Case of Neural Text Degeneration: https://arxiv.org/abs/1904.09751"
      ]
    }
  ]
}